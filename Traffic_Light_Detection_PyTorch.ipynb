{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9ce797",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'detectron2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-add02106425a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdetectron2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBoxMode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m# import tensorflow as tf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# from tensorflow.keras.layers import Input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'detectron2'"
     ]
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from detectron2.structures import BoxMode\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input\n",
    "# from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras import backend as K \n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "# from tensorflow.keras.layers import Dropout, Flatten, Activation\n",
    "# from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63523157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Set data path for our dataset that we will be using\n",
    "dataPath = 'C:/Users/Austin/HCL_TrafficLight/LISATrafficSet'\n",
    "sorted(os.listdir(dataPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set path for our annotated training folders\n",
    "dayTrainPath = dataPath + '/Annotations/Annotations/dayTrain'\n",
    "nightTrainPath = dataPath + '/Annotations/Annotations/nightTrain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the annotated files in all the Day Training folders \n",
    "# and set 'dayTime' feature to 1 since all during day time\n",
    "\n",
    "trainDayTime = []\n",
    "for dayFileName in sorted(os.listdir(dayTrainPath)):\n",
    "    if 'dayClip' in dayFileName:\n",
    "        df = pd.read_csv(os.path.join(dayTrainPath, dayFileName,'frameAnnotationsBOX.csv'),sep=';')\n",
    "        trainDayTime.append(df)\n",
    "    else:\n",
    "        continue\n",
    "trainDayTime_df = pd.concat(trainDayTime, axis=0)\n",
    "trainDayTime_df['dayTime'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b2552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure that 'dayTime' is set to 1\n",
    "trainDayTime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa513a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the annotated files in all the Night Training folders \n",
    "# and set 'dayTime' feature to 0 since all during night time\n",
    "\n",
    "trainNightTime = []\n",
    "for nightFileName in sorted(os.listdir(nightTrainPath)):\n",
    "    if 'nightClip' in nightFileName:\n",
    "        df = pd.read_csv(os.path.join(nightTrainPath, nightFileName,'frameAnnotationsBOX.csv'),sep=';')\n",
    "        trainNightTime.append(df)\n",
    "    else:\n",
    "        continue\n",
    "trainNightTime_df = pd.concat(trainNightTime, axis=0)\n",
    "trainNightTime_df['dayTime'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6ef6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to make sure that 'dayTime' is set to 0 since night time dataset\n",
    "trainNightTime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17bfcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have all of the day and night annotations combined respectively, we will combine \n",
    "# the two into create one large dataset\n",
    "combined_df = pd.concat([trainDayTime_df, trainNightTime_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acac8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if we have any missing values in our dataset\n",
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0c601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four of the columns in our dataframe appear to have the same values, we are checking here to confirm that they are the same\n",
    "print(df['Origin file'].equals(df['Origin track']))\n",
    "print(df['Origin frame number'].equals(df['Origin track frame number']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since they are the same values, we can drop the duplicate columns that we don't need\n",
    "combined_df = combined_df.drop(['Origin file','Origin track','Origin frame number','Origin track frame number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eae394d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df.columns = ['id', 'signal', 'left_x', 'left_y','right_x','right_y','dayTime']\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8680e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['signal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23febfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change classes to an integer\n",
    "label_to_idx = {'go':1, 'warning':2, 'stop': 3}\n",
    "idx_to_label = {v:k for k,v in label_to_idx.items()}\n",
    "\n",
    "\n",
    "def changeSignal(rowLabel):\n",
    "    if rowLabel == 'go' or rowLabel == 'goLeft':\n",
    "        return 1\n",
    "    elif rowLabel == 'warning' or rowLabel == 'warningLeft':\n",
    "        return 2\n",
    "    elif rowLabel == 'stop' or rowLabel == 'stopLeft':\n",
    "        return 3\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "combined_df['signal'] = combined_df['signal'].apply(changeSignal)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777ada3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(combined_df['signal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b19fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to change the id name to fit clip name in datasets\n",
    "# dayTraining/dayClip1--00000.jpg ----> C:\\Users\\Austin\\HCL_TrafficLight\\LISATrafficSet\\dayTrain\\dayTrain\\dayClip1\\frames\\dayClip1--00000\n",
    "def updateName(fileName):\n",
    "    \n",
    "    # First we have to parse id to obtain which clip folder and which specific frame\n",
    "    folder, frameName = fileName.split('/')\n",
    "    frameDir, clipId = frameName.split('--')\n",
    "    \n",
    "    if folder == 'dayTraining':\n",
    "        newFileName = dataPath + '/dayTrain/dayTrain/{0}/frames/{1}'.format(frameDir, frameName)\n",
    "    else:\n",
    "        newFileName = dataPath + '/nightTrain/nightTrain/{0}/frames/{1}'.format(frameDir, frameName)\n",
    "    \n",
    "    \n",
    "    return newFileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95d684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['id']= combined_df.id.apply(updateName)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b2742f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "im=\"C:/Users/Austin/HCL_TrafficLight/LISATrafficSet/dayTrain/dayTrain/dayClip1/frames/dayClip1--00000.jpg\"\n",
    "display(Image.open(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397bc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('C:/Users/Austin/HCL_TrafficLight/LISATrafficSet/dayTrain/dayTrain/dayClip1/frames/dayClip1--00000.jpg',1)\n",
    "# img = cv2.resize(img, (0,0), fx=0.5,fy=0.5)\n",
    "# img = cv2.rotate(img, cv2.cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "# cv2.imshow('Image', img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a41ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoTags = combined_df['signal'].unique()\n",
    "annoTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_bbox(img, boxes):\n",
    "#     boxes = boxes.split()\n",
    "#     boxes = [512 * float(i) for i in boxes]\n",
    "#     y = boxes[0]# * 512\n",
    "#     x = boxes[1]# * 512\n",
    "#     h = (boxes[2] - boxes[0])# * 512\n",
    "#     w = (boxes[3] - boxes[1])# * 512\n",
    "#     shape = [(x, y), (w, h)]\n",
    "#     print(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af6c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleBoxes(df):\n",
    "    fig, ax = plt.subplots(3, 1, figsize=(15,15))\n",
    "\n",
    "    for i, tag in enumerate(annoTags):\n",
    "    #   Take random sample from dataset to annotate\n",
    "        sample = df[df['signal']==tag].sample(1)\n",
    "        bbox = sample[['left_x', 'left_y','right_x','right_y']].values[0]\n",
    "\n",
    "    #   Change color of image to fit RGB color space\n",
    "        image = cv2.imread(sample.id.values[0])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #   Change color of box depending on signal value\n",
    "        if sample['signal'].values[0] == 1:\n",
    "            boxColor = (0,255,0)\n",
    "        elif sample['signal'].values[0] == 2:\n",
    "            boxColor = (255,255,0)\n",
    "        elif sample['signal'].values[0] == 3:\n",
    "            boxColor = (255,0,0)\n",
    "\n",
    "        cv2.rectangle(image, \n",
    "                      (bbox[0],bbox[1]), \n",
    "                      (bbox[2],bbox[3]), \n",
    "                      boxColor, 2)\n",
    "\n",
    "        ax[i].set_title(idx_to_label[tag])\n",
    "        ax[i].set_axis_off()\n",
    "        ax[i].imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1698a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleBoxes(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nameSplit(frameId):\n",
    "    clipName = frameId.split('/')[7]\n",
    "    return clipName\n",
    "\n",
    "combined_df['clipNames'] = sorted(combined_df['id'].apply(nameSplit))\n",
    "combined_df['clipNames'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b622d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split our dataframe into test and training sets\n",
    "def splitTestTrain(df):\n",
    "    clipNames = combined_df['clipNames'].unique()\n",
    "    nightClips = []\n",
    "    dayClips = []\n",
    "\n",
    "    for name in clipNames:\n",
    "        if 'day' in name:\n",
    "            dayClips.append(name)\n",
    "        else:\n",
    "            nightClips.append(name)\n",
    "\n",
    "    # Select random clip names from day and night folders to use for test set\n",
    "    testNightClipNames = random.choices(nightClips, k=int(len(nightClips)*0.25))\n",
    "    testDayClipNames = random.choices(dayClips, k=int(len(dayClips)*0.25))\n",
    "    testClipNames = testDayClipNames + testNightClipNames\n",
    "\n",
    "    train_df = combined_df[~combined_df['clipNames'].isin(testClipNames)]\n",
    "    test_df = combined_df[combined_df['clipNames'].isin(testClipNames)]\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = splitTestTrain(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape[0]/combined_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7a03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = splitTestTrain(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b812db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train: {0}, Valid: {1}\".format(train_df.shape,valid_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe8a2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_traffic_lights:\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.dim = (224,224)\n",
    "        self.ids = df.id.unique()\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        imageID = self.id[idx]\n",
    "        \n",
    "        \n",
    "        landmarkid = self.df.iloc[idx].id\n",
    "        url = self.df[self.df.id == id].url.values[0]\n",
    "        boxes = self.df[self.df.id == id].box.values[0]\n",
    "        print(\"enters get item with id \" + str(id))\n",
    "\n",
    "        boxes = self.format_boxes(boxes, self.dim)\n",
    "\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = torch.as_tensor([boxes], dtype=torch.int64)\n",
    "        #target[\"labels\"] = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        target[\"image_id\"] = torch.tensor([idx])\n",
    "\n",
    "        image = self.url_to_image(url, self.dim)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.id.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77453c94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef4d132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
